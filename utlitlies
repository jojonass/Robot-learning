import numpy as np
from collections import defaultdict
from stable_baselines3.common.callbacks import BaseCallback, EvalCallback


class SuccessCallback(BaseCallback):
    def __init__(self, log_freq=10000, verbose=0):
        super().__init__(verbose)
        self.log_freq = log_freq
        self.task_successes = defaultdict(list)
        self.env_current_success = defaultdict(float)

    def _on_step(self) -> bool:
        infos = self.locals.get("infos", [])
        dones = self.locals.get("dones", [])

        for i, info in enumerate(infos):
            if "task_name" in info and "success" in info:
                self.env_current_success[i] = max(self.env_current_success[i], info["success"])

        for i, done in enumerate(dones):
            if done:
                info = infos[i]
                if "task_name" in info:
                    task = info["task_name"]
                    self.task_successes[task].append(self.env_current_success[i])
                self.env_current_success[i] = 0.0

        if self.num_timesteps % self.log_freq == 0:
            self._log_success_rates()
        return True

    def _log_success_rates(self):
        total = []
        for task, successes in self.task_successes.items():
            if successes:
                rate = np.mean(successes[-100:])
                self.logger.record(f"success/{task}", rate)
                total.append(rate)
        if total:
            self.logger.record("success/mean_MT10", np.mean(total))


class EvalSuccessCallback(EvalCallback):
    def _on_step(self) -> bool:
        result = super()._on_step()
        if self.n_calls % self.eval_freq == 0:
            self._run_eval_success()
        return result

    def _run_eval_success(self):
        task_success = defaultdict(list)
        for _ in range(self.n_eval_episodes):
            obs_result = self.eval_env.reset()
            obs = obs_result[0] if isinstance(obs_result, tuple) else obs_result
            done = False

            while not done:
                action, _ = self.model.predict(obs, deterministic=True)
                step_result = self.eval_env.step(action)

                if len(step_result) == 5:
                    obs, reward, terminated, truncated, info = step_result
                else:
                    obs, reward, terminated, info = step_result
                    truncated = False

                if info.get("success", 0) > 0:
                    task_success[info["task_name"]].append(1.0)
                    break

                done = terminated or truncated

            if not info.get("success", 0) > 0:
                task_success[info["task_name"]].append(0.0)

        means = []
        for task, values in task_success.items():
            mean = np.mean(values)
            self.logger.record(f"eval_success/{task}", mean)
            means.append(mean)
        if means:
            self.logger.record("eval_success/mean_MT10", np.mean(means))
        self.logger.dump(self.num_timesteps)
